{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Stock Exchange\n",
    "\n",
    "Long have analysts, traders, and investors tried to predict future stock prices. Even if you come up with a plan or model that works for a while, it is generally great until for some reason it doesn't work. Whether there was a break down in underlying correlations or new news of scandal caused stock prices to plummet. If you could crack the whole code you'd be a billionaire in about the same amount of time as it takes to click on your favorite Netflix program. \n",
    "\n",
    "If any type of model is going to be able to finally do it, I would be willing to bet that model would fall into the deep learning category. So that is exactly what we are going to try to do.  \n",
    "\n",
    "\n",
    "## The Data\n",
    "The data set we will be working with is from the New York Stock Exchange (NYSE) and represent the historical prices and other fundamental data points of the S&P 500 from 2010 to the end of 2016.\n",
    "\n",
    "Dataset consists of following files:\n",
    "\n",
    "prices.csv: raw, as-is daily prices. Most of data spans from 2010 to the end of 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.\n",
    "\n",
    "prices-split-adjusted.csv: same as prices, but there have been added adjustments for splits. securities.csv: general description of each company with division on sectors\n",
    "\n",
    "fundamentals.csv: metrics extracted from annual SEC 10K filings (2012-2016), should be enough to derive most of popular fundamental indicators.\n",
    "\n",
    "The majority of our focus will be on the prices-split-adjusted.csv file, as this contains the adjusted prices for the stocks we will be trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Process\n",
    "\n",
    "This project will statisfy the third project requirement for the Data Science Bootcamp at the Flatiron School\n",
    "\n",
    "In General, we will follow the Data Science process, Cleaning, Exploring, and Analyzing iteratively until we arrive at a useable model.  \n",
    "\n",
    "As always we can begin by importing all the necessary libraries for our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(style='whitegrid')\n",
    "sns.set_palette('Set1')\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
